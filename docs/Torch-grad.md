# Torch grad  

Автоматическое дифференцирование

Механизм автоматического дифференцирования находится в модуле torch.autograd. С помощью него можно автоматически считать производны, что необходимо для многих задач оптимизации, в том числе для обучения нейронных сетей.

Все тензоры содержат в себе атрибут .requires_grad. Если обозначить его как `True`, то все операции над тензорами начнут сохраняться в граф вычислений, и при вызове `.backward()` выполнит обратный проход и посчитает производную по всем переменным, при создании которых мы указали `requires_grad=True`. Производная при этом запишется в свойство `x.grad`. Получить же свой тензор обратно мы можем используя свойство `x.data`. Свойство `x.requires_grad` покажет, нуждается ли узел графа в вычислении градиента. Правило такое: если хоть у одного дочернего узла это свойство установлено, оно будет установлено и у родителя.

Если обернуть тензоры в `Variable` то он сам позаботится о сохранении всех методов и свойств, и будет записывать все операции.

Что бы тензор не отслеживал историю, вы можете вызвать метод `.detach()`, что бы отделить историю вычислений от тензора. Так же это остановит дальнейшее отслеживание вычислений.

Что бы предотвратить отслеживание истории и использование памяти, вы можете обернуть блок кода в `with torch.no_grad():`. Это может быть полезно при оценке модели, так как модель может иметь обучающиеся параметры с requires_grad=True, но для которых не нужно считать градиент.

`Tensor` и `Function` взаимосвязаны и строятся как ациклический граф, который кодирует историю вычислений. Каждый тензор имеет атрибут `.grad_fn` который ссылается на функцию, которая создала тензор(исключение тензор который создал пользователь, тогда `grad_fn is None`).

Поскольку при вызове `backward()` устанавливается член `grad` у `Variables`, также существует метод `nn.Module.zero_grad()`, он обнуляет всю историю подсчёта градиентов. Обычно этот метод вызывается перед вызовом `backward()`, чтобы можно было провести следующий шаг оптимизации.

На данный момент autograd поддерживается только для тензоров с плавающей запятой (half, float, double и bfloat16) и сложных тензоров типов (cfloat, cdouble).

Пример:

```
import torch
from torch.autograd import Variable
T = torch.Tensor([[1., 2.], [2., 3.]])
T = Variable(T, requires_grad=True)
print(T.requires_grad) 
True

T1 = torch.sqrt(T)
print(T1)  
tensor([[1.0000, 1.4142],
        [1.4142, 1.7321]], grad_fn=<SqrtBackward>)

T2 = T1.sum()
print(T2)
tensor(5.5605, grad_fn=<SumBackward0>)

T2.backward()
print(T.grad)
tensor([[1.5000, 1.3536],
        [1.3536, 1.2887]])
```

Разберём пример подробнее:

После импорта библиотек инициализируем тензор T, оборачиваем его в Variable и обозначаем переменную requires_grad=True для записи графа действий.
```
T = torch.Tensor([[1., 2.], [2., 3.]])
T = Variable(T, requires_grad=True)
print(T.requires_grad)

True
```
Проводим операцию взятия корня. Как можно видеть теперь в тензоре хранится последнее действие с ним, в данном случае взятие корня (grad_fn=<SqrtBackward>).

```
T1 = torch.sqrt(T)
print(T1)  
tensor([[1.0000, 1.4142],
        [1.4142, 1.7321]], grad_fn=<SqrtBackward>)
```

Так как .backward() работает только со скалярными значениями, то проводим операцию суммы. Как можно видеть тензор сохранил эту операцию

```
T2 = T1.sum()
print(T2)
tensor(5.5605, grad_fn=<SumBackward0>)
```

Вычисляем градиенты с помощью .backward() и выводим на экран посчитанные градиенты для T.

```
T2.backward()
print(T.grad)
tensor([[1.5000, 1.3536],
        [1.3536, 1.2887]])
```